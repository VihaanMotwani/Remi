import speech_recognition as sr
import re, time, json, os
from agents.daily_agent import compile_daily_context
from core.llm_client import generate_daily_voice_summary

def listen_and_route():
    """
    ğŸ§ Remi voice interface (streaming edition)
    - Listens once for a command
    - Determines the focus (tasks, calendar, or day)
    - Streams Gemini + ElevenLabs response live
    """
    r = sr.Recognizer()
    mic = sr.Microphone()

    print("ğŸ™ Remi is listeningâ€¦ say something like 'what are my tasks for today' or 'what does my day look like'.")
    with mic as source:
        print("ğŸ§ Calibrating ambient noise... (1.5s)")
        r.adjust_for_ambient_noise(source, duration=1.5)
        print("ğŸ¤ Listening for your voice...")

        try:
            audio = r.listen(source, timeout=8, phrase_time_limit=8)
        except sr.WaitTimeoutError:
            print("âŒ› Timeout â€” no speech detected. Exiting.")
            return

        try:
            text = r.recognize_google(audio).lower()
            print(f"Heard: {text}")

            # --- Determine focus intent ---
            if "task" in text:
                focus = "tasks"
            elif "calendar" in text or "meeting" in text or "schedule" in text:
                focus = "calendar"
            else:
                focus = "day"

            print(f"ğŸ§  Command detected: {text}")
            print(f"ğŸ¯ Focus area: {focus}")

            # --- Compile context from database ---
            context = compile_daily_context()

            # --- Stream Gemini + ElevenLabs live ---
            print("ğŸ—£ï¸ Generating and speaking response in real time...")
            summary_text = generate_daily_voice_summary(context, focus)

            print("\nğŸ Done â€” Remi has finished responding. Exiting.")

        except sr.UnknownValueError:
            print("âŒ Could not understand speech.")
        except Exception as e:
            print(f"âŒ Voice agent error: {e}")
